{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test rig anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('\\\\Users\\\\iokhotnikov\\\\Documents\\\\Python\\\\hhl\\\\test_rig\\\\code')\n",
    "from scripts.utils.readers import DataReader, Preprocessor\n",
    "from scripts.utils.config import FEATURES, FEATURES_NO_TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('\\\\Users\\\\iokhotnikov\\\\Documents\\\\Python\\\\hhl\\\\test_rig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(mode='preprocessed'):\n",
    "    if mode == 'raw':\n",
    "        df = DataReader.read_all_raw_data(verbose=True,\n",
    "                                          features_to_read=FEATURES)\n",
    "        df = Preprocessor.remove_step_zero(df, inplace=False)\n",
    "        df.sort_values(by=['DATE', 'TIME'], inplace=True, ignore_index=True)\n",
    "    if mode == 'processed':\n",
    "        df = pd.read_csv(os.path.join('data', 'processed',\n",
    "                                      'combined_timed_data.csv'),\n",
    "                         parse_dates=True,\n",
    "                         infer_datetime_format=True,\n",
    "                         dtype=dict(\n",
    "                             zip(FEATURES_NO_TIME,\n",
    "                                 [np.float32] * len(FEATURES_NO_TIME))))\n",
    "        df[['STEP', 'UNIT', 'TEST',\n",
    "            'ARMANI']] = df[['STEP', 'UNIT', 'TEST',\n",
    "                             'ARMANI']].astype(np.uint8)\n",
    "        df['TIME'] = pd.to_datetime(df['TIME'])\n",
    "        df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df['RUNNING TIME'] = pd.date_range(start=f'{min(df[\"DATE\"])} 00:00:00',\n",
    "                                       periods=len(df),\n",
    "                                       freq='s')\n",
    "    df['RUNNING DURATION'] = pd.to_timedelta(range(len(df)), unit='s')\n",
    "    df['RUNNING HOURS'] = (\n",
    "        pd.to_timedelta(range(len(df)), unit='s').total_seconds() /\n",
    "        3600).astype(np.float32)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(mode='processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect and cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lengths = []\n",
    "step_lengths = []\n",
    "for unit in df['UNIT'].unique():\n",
    "    for unit_test in df[df['UNIT'] == unit]['TEST'].unique():\n",
    "        test_lengths.append(\n",
    "            len(df[(df['UNIT'] == unit) & (df['TEST'] == unit_test)]))\n",
    "        for step in df[(df['UNIT'] == unit)\n",
    "                       & (df['TEST'] == unit_test)]['STEP'].unique():\n",
    "            step_lengths.append(\n",
    "                len(df[(df['UNIT'] == unit) & (df['TEST'] == unit_test) &\n",
    "                       (df['STEP'] == step)]))\n",
    "mean_test_dur_sec = np.mean(test_lengths)\n",
    "mean_step_dur_sec = np.mean(step_lengths)\n",
    "print(\n",
    "    f'Mean test duration {mean_test_dur_sec:.2f} seconds = {mean_test_dur_sec/60:.2f} minutes = {mean_test_dur_sec/3600:.2f} hours'\n",
    ")\n",
    "print(\n",
    "    f'Mean step duration {mean_step_dur_sec:.2f} seconds = {mean_step_dur_sec/60:.2f} minutes = {mean_step_dur_sec/3600:.2f} hours'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature(df, feature):\n",
    "    plt.figure(figsize=(20, 5), tight_layout=True)\n",
    "    plt.plot(df['RUNNING HOURS'], df[feature])\n",
    "    plt.ylabel(feature)\n",
    "    plt.xlabel('TIME, HOURS')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_data(df):\n",
    "    for feature in df.columns:\n",
    "        if 'RUNNING' not in feature:\n",
    "            plot_feature(df, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_data(df[FEATURES_NO_TIME + ['RUNNING HOURS']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL_TREND_FEATURES = [\n",
    "#     'M1 CURRENT', 'M1 TORQUE', 'PT4', 'D1 RPM', 'D1 CURRENT', 'D1 TORQUE',\n",
    "#     'M2 RPM', 'M2 Amp', 'M2 Torque', 'CHARGE PT', 'CHARGE FLOW', 'M3 Amp',\n",
    "#     'M3 Torque', 'Servo PT', 'SERVO FLOW', 'HSU IN', 'TT2', 'HSU OUT',\n",
    "#     'M5 Amp', 'M5 Torque', 'M6 RPM', 'M6 Amp', 'M6 Torque', 'M7 RPM', 'M7 Amp',\n",
    "#     'M7 Torque', 'Vibration 1', ' Vibration 2'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENGINEERED_FEATURES = [\n",
    "#     'DRIVE POWER', 'LOAD POWER', 'CHARGE MECH POWER', 'CHARGE HYD POWER',\n",
    "#     'SERVO MECH POWER', 'SERVO HYD POWER', 'SCAVENGE POWER',\n",
    "#     'MAIN COOLER POWER', 'GEARBOX COOLER POWER'\n",
    "# ]\n",
    "# df['DRIVE POWER'] = (df['M1 SPEED'] * df['M1 TORQUE'] * np.pi / 30 /\n",
    "#                      1e3).astype(np.float32)\n",
    "# df['LOAD POWER'] = abs(df['D1 RPM'] * df['D1 TORQUE'] * np.pi / 30 /\n",
    "#                        1e3).astype(np.float32)\n",
    "# df['CHARGE MECH POWER'] = (df['M2 RPM'] * df['M2 Torque'] * np.pi / 30 /\n",
    "#                            1e3).astype(np.float32)\n",
    "# df['CHARGE HYD POWER'] = (df['CHARGE PT'] * 1e5 * df['CHARGE FLOW'] * 1e-3 /\n",
    "#                           60 / 1e3).astype(np.float32)\n",
    "# df['SERVO MECH POWER'] = (df['M3 RPM'] * df['M3 Torque'] * np.pi / 30 /\n",
    "#                           1e3).astype(np.float32)\n",
    "# df['SERVO HYD POWER'] = (df['Servo PT'] * 1e5 * df['SERVO FLOW'] * 1e-3 / 60 /\n",
    "#                          1e3).astype(np.float32)\n",
    "# df['SCAVENGE POWER'] = (df['M5 RPM'] * df['M5 Torque'] * np.pi / 30 /\n",
    "#                         1e3).astype(np.float32)\n",
    "# df['MAIN COOLER POWER'] = (df['M6 RPM'] * df['M6 Torque'] * np.pi / 30 /\n",
    "#                            1e3).astype(np.float32)\n",
    "# df['GEARBOX COOLER POWER'] = (df['M7 RPM'] * df['M7 Torque'] * np.pi / 30 /\n",
    "#                               1e3).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREND_FEATURES = ENGINEERED_FEATURES + [\n",
    "#     'PT4', 'HSU IN', 'TT2', 'HSU OUT', 'Vibration 1', ' Vibration 2'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Computing the number of samples we'll use for each data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df[TREND_FEATURES + ['RUNNING HOURS']].copy(deep=True)\n",
    "# raw_data = df[TREND_FEATURES].copy(deep=True)\n",
    "# vibration = raw_data.pop('Vibration 1')\n",
    "vibration = df.pop('Vibration 1').astype(np.float32)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vibration_mean = vibration.mean()\n",
    "vibration_std = vibration.std()\n",
    "train_vibration = (vibration - vibration_mean) / vibration_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vibration.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 3600\n",
    "\n",
    "def create_sequences(values, time_steps=TIME_STEPS):\n",
    "    output = []\n",
    "    for i in range(len(values) - time_steps + 1):\n",
    "        output.append(values[i : (i + time_steps)])\n",
    "    return np.stack(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = create_sequences(train_vibration.values.reshape(-1, 1))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    layers.LSTM(128, input_shape=(x_train.shape[1], x_train.shape[2])),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.RepeatVector(TIME_STEPS),  # replicates features from outputs (30 times)\n",
    "    layers.LSTM(128, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    # Time distributed layer to get an output with right shape\n",
    "    layers.TimeDistributed(layers.Dense(x_train.shape[2]))\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,\n",
    "                    x_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[\n",
    "                        keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                      patience=5,\n",
    "                                                      mode=\"min\")\n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PF7v1QbT5XXo"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train MAE loss.\n",
    "x_train_pred = model.predict(x_train)\n",
    "train_mae_loss = np.mean(np.abs(x_train_pred - x_train), axis=1)\n",
    "\n",
    "plt.hist(train_mae_loss, bins=50)\n",
    "plt.xlabel(\"Train MAE loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()\n",
    "\n",
    "# Get reconstruction loss threshold.\n",
    "threshold = np.max(train_mae_loss)\n",
    "print(\"Reconstruction error threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how the first sequence is learnt\n",
    "plt.plot(x_train[2])\n",
    "plt.plot(x_train_pred[2])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38740d3277777e2cd7c6c2cc9d8addf5118fdf3f82b1b39231fd12aeac8aee8b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
